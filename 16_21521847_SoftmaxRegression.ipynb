{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fKmmFnbRwp5Y","outputId":"ab8074ea-e482-43e4-ae0a-749990fc6a92","executionInfo":{"status":"ok","timestamp":1734033490945,"user_tz":-420,"elapsed":21191,"user":{"displayName":"Võ Hồng Kim Anh","userId":"13867913512765584752"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# kết nối ggdrive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k3EaF89EyOlJ","executionInfo":{"status":"ok","timestamp":1734033497320,"user_tz":-420,"elapsed":6377,"user":{"displayName":"Võ Hồng Kim Anh","userId":"13867913512765584752"}},"outputId":"b8793a80-3e61-4b66-c85e-8641e7ecf342"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting spark\n","  Downloading spark-0.2.1.tar.gz (41 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: spark\n","  Building wheel for spark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for spark: filename=spark-0.2.1-py3-none-any.whl size=58748 sha256=f5590c74cd26f3ff8ec2897b554fce10dc0addad7d0fe1264b1e59aa9eaa3bc1\n","  Stored in directory: /root/.cache/pip/wheels/63/88/77/b4131110ea4094540f7b47c6d62a649807d7e94800da5eab0b\n","Successfully built spark\n","Installing collected packages: spark\n","Successfully installed spark-0.2.1\n"]}],"source":["!pip install spark"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iyqrfs5r8MXb","executionInfo":{"status":"ok","timestamp":1734033503246,"user_tz":-420,"elapsed":5935,"user":{"displayName":"Võ Hồng Kim Anh","userId":"13867913512765584752"}},"outputId":"dab879dc-2afb-42bd-98a2-0189222ec820"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"]}],"source":["pip install pyspark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5oYFVJiUw03G"},"outputs":[],"source":["# Import các thư viện cần thiết\n","from pyspark import SparkContext, SparkConf\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os"]},{"cell_type":"markdown","metadata":{"id":"RjPXklr5yKte"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0nZJzOhEYEGi"},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql import functions as F\n","from pyspark.sql.types import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"be8sEHZcW_s_"},"outputs":[],"source":["MAIN_PATH = \"/content/gdrive/MyDrive/BigData_FlightDelay\"\n","DATA_TRAIN_PATH = os.path.join(MAIN_PATH,\"train_data.csv\")\n","DATA_TEST_PATH = os.path.join(MAIN_PATH,\"test_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LDsTXvVpX2ki"},"outputs":[],"source":["spark = SparkSession.builder.appName(\"Spark Solfmax\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z46fcUvrX9Qu"},"outputs":[],"source":["data = spark.read.option(\"header\", True).csv(DATA_TRAIN_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kqcEZ-4Yg2S","executionInfo":{"status":"ok","timestamp":1734033540094,"user_tz":-420,"elapsed":1216,"user":{"displayName":"Võ Hồng Kim Anh","userId":"13867913512765584752"}},"outputId":"28016916-8165-45cf-ec5a-3e40f857775c"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+-----+\n","|            features|LABEL|\n","+--------------------+-----+\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    1|\n","|(702,[0,1,2,3,4,5...|    1|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    2|\n","|(702,[0,1,2,3,4,5...|    1|\n","|(702,[0,1,2,3,4,5...|    1|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    2|\n","|(702,[0,1,2,3,4,5...|    2|\n","|(702,[0,1,2,3,4,5...|    2|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    0|\n","|(702,[0,1,2,3,4,5...|    2|\n","+--------------------+-----+\n","only showing top 20 rows\n","\n"]}],"source":["data.show(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yz-r-_YptbXG"},"outputs":[],"source":["# Function to parse the vector string dynamically\n","def parse_vector_string(vector_str):\n","    vector_str = vector_str.strip('()')\n","    # Split into size, indices, and values\n","    parts = vector_str.split(',[', 2)\n","    size = int(parts[0].strip('['))\n","    indices = list(map(int, parts[1].strip(']').split(',')))\n","    values = list(map(float, parts[2].strip(']').split(',')))\n","    full_vector = [0.0] * size\n","    for idx, val in zip(indices, values):\n","        full_vector[idx] = val\n","    return full_vector\n","\n","# Register UDF\n","parse_vector_udf = udf(parse_vector_string, ArrayType(DoubleType()))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hj6_FKlfUqDw"},"outputs":[],"source":["def parse_vector_string_rdd(vector_str):\n","    vector_str = vector_str.strip('\"()')\n","    # Split into size, indices, and values\n","    parts = vector_str.split(',[', 2)\n","    size = int(parts[0].strip('['))\n","    indices = list(map(int, parts[1].strip(']').split(',')))\n","    values = list(map(float, parts[2].strip(']').split(',')))\n","    full_vector = [0.0] * size\n","    for idx, val in zip(indices, values):\n","        full_vector[idx] = val\n","    return full_vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EIXF8b1C8wiT"},"outputs":[],"source":["fileRDD = spark.sparkContext.textFile(os.path.join(DATA_TRAIN_PATH))\n","# Skip the header and split the lines into lists of strings\n","dataRDD = fileRDD.filter(lambda line: 'features,LABEL' not in line).map(lambda line: (parse_vector_string_rdd(line.split('\",')[0]),int(line.split('\",')[1])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JdA7_zkl5f-C"},"outputs":[],"source":["testRDD = spark.sparkContext.textFile(os.path.join(DATA_TEST_PATH))\n","# Skip the header and split the lines into lists of strings\n","datatestRDD = testRDD.filter(lambda line: 'features,LABEL' not in line).map(lambda line: (parse_vector_string_rdd(line.split('\",')[0]),int(line.split('\",')[1])))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NYGxYCTq9C6f","executionInfo":{"status":"ok","timestamp":1734033556192,"user_tz":-420,"elapsed":3717,"user":{"displayName":"Võ Hồng Kim Anh","userId":"13867913512765584752"}},"outputId":"9b549457-c1f3-4e88-e246-b407359e3809"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+-----+\n","|            features|LABEL|\n","+--------------------+-----+\n","|[1.0, 11.0, 1413....|    0|\n","|[1.0, 14.0, 608.0...|    0|\n","|[1.0, 16.0, 1031....|    0|\n","|[1.0, 30.0, 2132....|    1|\n","|[2.0, 11.0, 628.0...|    1|\n","|[2.0, 18.0, 1028....|    0|\n","|[2.0, 18.0, 2107....|    0|\n","|[3.0, 11.0, 1342....|    0|\n","|[3.0, 11.0, 1700....|    2|\n","|[3.0, 11.0, 1918....|    1|\n","|[3.0, 12.0, 640.0...|    1|\n","|[3.0, 13.0, 842.0...|    0|\n","|[4.0, 21.0, 1820....|    0|\n","|[5.0, 13.0, 936.0...|    0|\n","|[5.0, 14.0, 1951....|    2|\n","|[5.0, 24.0, 1430....|    2|\n","|[6.0, 12.0, 2002....|    2|\n","|[6.0, 15.0, 645.0...|    0|\n","|[6.0, 16.0, 2118....|    0|\n","|[6.0, 21.0, 1429....|    2|\n","+--------------------+-----+\n","only showing top 20 rows\n","\n"]}],"source":["# Add parsed feature column to DataFrame\n","data_train = data.withColumn(\"features\", parse_vector_udf(data.features))\n","data_train=data_train.withColumn(\"LABEL\", col(\"LABEL\").cast(\"int\"))\n","#show\n","data_train.show()"]},{"cell_type":"markdown","source":["# **Softmax Regression**"],"metadata":{"id":"KOToLpd6RzXz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOSk0rv5zhlS"},"outputs":[],"source":["def softmax(z):\n","    exp_z = np.exp(z - np.max(z))\n","    return exp_z / exp_z.sum(axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZL5RDaDtqvW"},"outputs":[],"source":["def execute_softmax_regression(rdd, Weights_init, eta, tolerance=1e-4, max_count=100):\n","    spark_ctx = rdd.context\n","    Weights = Weights_init\n","    C = Weights_init.shape[1] #Số lớp (num_classes)\n","    N = rdd.count() #Số mẫu dữ liệu trong tập huấn luyện (RDD)\n","    input_size = len(rdd.first()[0]) #Số đặc trưng (num_features)\n","\n","    count = 0\n","    check_weights_after = 20\n","    Weights_broadcast = spark_ctx.broadcast(Weights) #Chia sẻ W đến các worker node mà k cần truyền nhiều lần\n","\n","    def compute_gradient(record):\n","        xi, label = record\n","        xi = np.array(xi).reshape(input_size, 1)\n","        yi = np.zeros((C, 1)) #vector cột y kích thước (C,1) slg lớp\n","        yi[label] = 1\n","        ai = softmax(np.dot(Weights_broadcast.value.T, xi))\n","        gradient = xi.dot((yi - ai).T)\n","        return gradient\n","\n","    while count < max_count:\n","        gradients = rdd.map(compute_gradient).reduce(lambda g1, g2: g1 + g2)\n","        Weights_new = Weights + eta * gradients\n","\n","        count += 1\n","\n","        if count % (check_weights_after * N) == 0:\n","            if np.linalg.norm(Weights_new - Weights) < tolerance: #Kiểm tra điều kiện hội tụ\n","                return Weights_new\n","\n","        Weights = Weights_new\n","        Weights_broadcast = spark_ctx.broadcast(Weights)\n","\n","    return Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0QUpd2tuIaH"},"outputs":[],"source":["# Khởi tạo tham số\n","num_features = len(dataRDD.first()[0])\n","num_classes = dataRDD.map(lambda x: x[1]).distinct().count() #lấy nhãn từ dataRDD khác nhau\n","Weights_init = np.random.randn(num_features, num_classes)\n","eta = 0.01\n","tolerance = 1e-4\n","max_count = 1000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6qCCCmNvG16"},"outputs":[],"source":["Weights_final = execute_softmax_regression(dataRDD, Weights_init, eta, tolerance, max_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-cji95bX4Io7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734040114465,"user_tz":-420,"elapsed":1,"user":{"displayName":"Võ Hồng Kim Anh","userId":"13867913512765584752"}},"outputId":"5ae14b28-46ea-445f-bcf2-15fb9a0053a1"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Final weights: [[ 6.26321143e+03 -4.22380276e+02 -5.84395837e+03]\n"," [-5.56118676e+04  1.18685146e+04  4.37450048e+04]\n"," [-2.14080551e+04 -2.75053271e+04  4.89149102e+04]\n"," ...\n"," [ 5.43640690e-03  2.58197189e-03  3.88709027e-01]\n"," [-6.39608746e-01  1.51941750e+00  4.77937039e-01]\n"," [ 5.97548577e+04 -2.92422393e+04 -3.05100524e+04]]\n"]}],"source":["print(\"Final weights:\", Weights_final)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJ_rVrRA4ym0"},"outputs":[],"source":["# Hàm predict label\n","def predict(x, Weights):\n","    scores = np.dot(Weights.T, x) # tính W^tX\n","    return np.argmax(softmax(scores), axis=0) #Dự đoán nhãn bằng cách chọn lớp có xác suất cao nhất"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"drGglTIW6q21"},"outputs":[],"source":["def calculate_metrics(confusion_matrix):\n","    num_classes = confusion_matrix.shape[0]\n","\n","    precision = np.zeros(num_classes)\n","    recall = np.zeros(num_classes)\n","    f1 = np.zeros(num_classes)\n","\n","    for i in range(num_classes):\n","        tp = confusion_matrix[i, i]\n","        fp = np.sum(confusion_matrix[:, i]) - tp\n","        fn = np.sum(confusion_matrix[i, :]) - tp\n","        tn = np.sum(confusion_matrix) - (tp + fp + fn)\n","\n","        precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n","        recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n","        f1[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n","\n","    accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n","    macro_precision = np.mean(precision)\n","    macro_recall = np.mean(recall)\n","    macro_f1 = np.mean(f1)\n","\n","    return accuracy, macro_precision, macro_recall, macro_f1\n","\n","def evaluate_model(test_rdd, Weights):\n","    spark_ctx = test_rdd.context\n","\n","    def predict_label(record):\n","        xi, label = record\n","        xi = np.array(xi).reshape(len(xi), 1)\n","        predicted_label = predict(xi, Weights)\n","        return (predicted_label, label) #trả về cặp dự đoán và nhãn thật.\n","\n","    predictions_and_labels = test_rdd.map(predict_label).collect()\n","\n","    predictions = [pred for pred, label in predictions_and_labels]\n","    true_labels = [label for pred, label in predictions_and_labels]\n","\n","    num_classes = len(set(true_labels))\n","    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n","\n","    for true, pred in zip(true_labels, predictions):\n","        confusion_matrix[true, pred] += 1\n","\n","    accuracy, precision, recall, f1 = calculate_metrics(confusion_matrix)\n","\n","    return accuracy, precision, recall, f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9szVr5XQ6wUU"},"outputs":[],"source":["accuracy, precision, recall, f1 = evaluate_model(datatestRDD, Weights_final)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDQwm_W49d4W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734040117190,"user_tz":-420,"elapsed":4,"user":{"displayName":"Võ Hồng Kim Anh","userId":"13867913512765584752"}},"outputId":"721a192b-9974-46a9-f37b-713721ea1902"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.5394996708360764\n","Precision: 0.28519371845025243\n","Recall: 0.3384095738905177\n","F1-score: 0.2597318531835001\n"]}],"source":["print(f\"Accuracy: {accuracy}\")\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"F1-score: {f1}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hULarz9hclBR"},"outputs":[],"source":["spark.stop()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}